# survey learning system

# 1. 개요

- 설문점수 같은 부류의 기계학습에서 가장 문제가 되는 것은 참여도 및 성실도가 낮은 데이터들로 인해, 학습이 적절하게 이루어지지 않는다는 점이 존재한다.
  → 참여도 및 성실도가 낮은 데이터들을 노이즈로서 제거를 하고, 나머지 데이터들로 통해서 학습이 적절하게 이루어지도록 해야한다.
- 기계학습 중 한 종류인 랜덤포레스트(Random Forest)를 이용하면 특징 중요도(feature importance)를 측정할 수가 있는데, 이를 활용하여 참여도가 낮은 데이터들을 분리하고, 참여도가 높은 데이터들의 구성으로 학습을 시키는 구성을 소개한다.

# 2. Random Forest

> Random Forest는 수많은 의사결정트리(Decision Tree)모여서 생성되는 숲이다.

- Random Forest는 수많은 Feature 중, 랜덤으로 n개의 feature만 선택해서 하나의 결정 트리를 만들고, 또 수많은 feature 중, n개의 feature를 선택해서 또 다른 트리를 만들고를 반복하여 여러 개의 결정 트리를 만든다.
- 이렇게 늘어난, 결정트리 하나마다 예측 값을 내놓을 것이다. 여러 결정 트리들이 내린 예측 값들 중 가장 많이 나온 값을 최종 예측값으로 정한다.
  - 다수결의 원칙에 따르는 것
  - 이와 같이, 강력한 하나의 모델을 사용하는대신, 약한 모델 여러개를 조합하여 예측하는 방식을 앙상블(Ensemble)학습법이라 한다.
- Random Forest 모델의 장점 중 하나는 학습과정에서 Label을 예측하기 위해 쓰인 특징들별로 중요도를 확인할 수 있다는 것 이다.

# 3. 사용자 만족도 예측모델

## 1. 임의의 사용자 객체 구성

> 많은 특성들이 있지만, 해당 예제에서는 온도(temp),습도(hum),조도(lux)만 이용했다.

- 설문점수는 각 카테고리 별로 20점씩 해서 60점이 만점이다.
- 임의의 데이터 생성을 위한 사용자 객체는 아래와 같은 인자를 받아 생성된다.
  | 이름 | 설명 |
  | ------------------- | ------------------------------- |
  | user_id | 사용자 식별을 위한 고유 번호 |
  | importance_features | 사용자가 중요하게 생각하는 특성 |
- 온도, 습도, 조도 중 한 개 혹은 여러개의 특성을 importance_features에 담아서 만들어진 사용자는 해당 특성에 대해서는 반드시 실내 적정값을 맞추어야 20점을 부여하는 특징을 가지고 있다.
  > **일반적인 실내 적정값**
  > 온도 : 18 ~ 20 / 습도 : 40 ~ 60 / 조도 : 700 ~ 1500 (사무실)
  > 해당 적정값이 만족되지 않을 경우, 점수를 낮게 주도록 한다.
  > 온도 : 20 - ( 온도차 / 2 ) / 습도 : 20 - (습도차 / 5) / 조도 : 20 - (조도차 / 100)
  - importance_features 의 값이 비어있지 않은 사용자들은 모두 다른 특징에 대해서는 어떠한 값이든 상관없이 16~20점 사이의 점수를 랜덤하게 준다.
- importance_features가 빈배열일 경우, 설문조사에 참여도가 낮은 참여자로, 모든 설문점수를 한 줄로, 혹은 완전히 랜덤하게 설문조사에 참여한다.

```python
# 성실 참여자 50명 생성
users = list()
for user_id in range(0, 50):
    user = User(user_id, generate_features())
    users.append(user)

# 불성실 참여자 30명 생성
for user_id in range(50, 80):
    user = User(user_id, [])
    users.append(user)

# 매우불성실 참여자 20명 생성 (무조건 20점만을 주는 참여자)
for user_id in range(80, 100):
    user = User(user_id, [], True)
    users.append(user)
```

## 2. 사용자 설문조사

```python
for days in range(0, 540):
    now_after = now + dt.timedelta(days=days)
    str_after = dt.datetime.strftime(now_after, '%Y-%m-%d')

    # 온도 10~32
    ran_temp = ran.randrange(10, 33)

    # 습도 30 ~ 80
    ran_hum = ran.randrange(30, 81)

    # 조도 200 ~ 1900 (100 단위)
    ran_lux = ran.randrange(200, 1901, 100)

    for user in users:
        _s = user.score(ran_temp,
                       ran_hum,
                       ran_lux)
        user.save_survey(
            days,
            ran_temp,
            ran_hum,
            ran_lux,
            _s
        )
```

- 주석에 나와있는 숫자의 범위 만큼 랜덤하게 하루의 실내 온도, 습도, 조도가 결정되며, 위에 만들어진 참여자들은 해당 온도 습도 조도에 대한 설문조사를 실시하고, 이를 저장한다. 540일간의 설문조사 데이터를 임의로 만들어낸다.

## 3. 랜덤 포레스트 학습

![](https://user-images.githubusercontent.com/52296323/155922413-e70d5d30-30bb-4be5-9306-766f3428d0be.png)

> **learning features**

- no : 설문번호
- temp : 온도
- hum : 습도
- lux : 조도

> **label**

- score : 설문점수

> **100명의 참여자별로 랜덤 포레스트 모델을 학습 시킬 것 이다. 그러면 총 100개의 랜덤 포레스트 모델이 나오는데, 여기서 랜덤포레스트가 label을 예측하기 위해 쓰인 특징들 중 중요도가 높다고 평가한 특징들을 기록함으로써 임의로 생성한 참여도가 높은 사용자와 참여도가 낮은 사용자 간의 어떤 차이를 보이는지 확인해보도록 한다.**

1. 참여도가 높은 참여자

   > **참여도가 높은 참여자들은 참여자 리스트에 0~49 위치에 위치해 있다.**

   ![Untitled 2](https://user-images.githubusercontent.com/52296323/155922422-c11d7414-90de-4a66-a90a-0102697e82c6.png)

   - column description
     - imp features : 참여자가 중요하다고 생각하는 특징
     - RF imp features : RF 학습에서 특정 참여자 설문점수를 예측하는데에 가장 중요하게 쓰인 특징

   ```python
   part_user = _record[:50].copy()
   part_user[part_user['imp features'] == part_user['RF imp features']].count()
   ```

   - 참여도가 높은 모든 참여자들은 실제 참여자가 중요하게 생각하고 설문점수에 반영하는 특징들과 RF Model이 특징 변화에 따른 점수 예측을 학습할 때 가장 중요하게 사용했던 특징들은 같게 나왔다.

   ![참여도가 높은 50명의 사용자의 중요 특징과 RF 학습에 쓰인 중요 특징](https://user-images.githubusercontent.com/52296323/155922448-0bbdf1a8-ff26-474d-93ef-91749aa60d10.png)

   참여도가 높은 50명의 사용자의 중요 특징과 RF 학습에 쓰인 중요 특징

2. 참여도가 낮은 참여자

   > **참여도가 낮은 참여자들은 참여자 리스트에 50~99 위치에 위치해 있다.**

   ![설문조사를 무조건 1자로 기입하거나, 마구잡이로 점수를 부여하는 참여도가 낮은 참여자들](https://user-images.githubusercontent.com/52296323/155922479-3922cccd-d8b6-41b6-bffd-b1e9c623773d.png)

   설문조사를 무조건 1자로 기입하거나, 마구잡이로 점수를 부여하는 참여도가 낮은 참여자들

   - 참여도가 낮은 참여자들은 자신이 설문점수에 반영하는데 특징들을 반영하지 않는다. 그래서 이들을 RF Model 에 학습을 시키게 되면 매 설문조사 회차마다 점수가 달라지거나 같으므로, 변수 중요도로 설문점수번호(no)가 나타나는 것을 확인할 수 있었다. 또한 RF Model이 학습이 제대로 되지 않아 mse도 참여도가 높은 참여자들에 비해 높게 나오는 것을 확인할 수 있었다.

   ![설문조사를 무조건 1자로 기입하는 참여도가 낮은 참여자들](https://user-images.githubusercontent.com/52296323/155922504-66779b43-b262-4470-8ea7-72d79c743473.png)

   설문조사를 무조건 1자로 기입하는 참여도가 낮은 참여자들

   - 무조건 1자로 기입하는 참여도가 낮은 참여자들은 RF Model이 의사결정을 내릴때 하나의 점수로만 예측을 하면 됨으로 mse가 0값으로 나타나는 것을 확인할 수 있었고, 예측하는데에 특징을 사용하지 않기 때문에 모델이 모든 특징의 중요도를 0으로 측정해서 RF Model 상에도 중요특징이 나타나지 않은 것을 확인할 수 있었다.

   ![](https://user-images.githubusercontent.com/52296323/155922531-2264ac8f-eb43-4ff4-9069-6950756821be.png)

3. 설문조사 타깃 (특정 건물 또는 호) 학습

> **위에서 참여도가 높은 참여자와 참여도가 낮은 참여자를 구분해내는 방법을 랜덤포레스트 기계학습의 중요도를 통해서 소개했다. 해당 연구의 최종목표는 특정 건물 또는 호의 정확한 사용자 선호치를 알아내는 것이다. 이를 위에서 얻어낸 것들을 토대로 알아내는 방법을 소개한다.**

- **설문점수 평균치**
  > **참여도가 높은 참여자들만으로 설문점수를 평균을 내어, 이를 라벨로 사용하여, 위에서 사용한 특징들을 그대로 사용해서 랜덤포레스트 학습을 시키면, 특정 건물 또는 호의 참여도가 높은 참여자들이 선호하는 특징들 순으로 주요 특징을 확인할 수 있다.**
  > ![](https://user-images.githubusercontent.com/52296323/155922578-f6cb6fa8-4326-4c68-b1cf-4884d6efeee2.png)
  - 해당 랜덤포레스트의 결과로는 습도(hum) → 조도(lux) → temp(온도) 순으로 평균 설문점수를 예측하게 중요하게 쓰이는 특징들을 보여줬다.
    ![Untitled 8](https://user-images.githubusercontent.com/52296323/155922606-691b5aae-c737-4375-a857-835290b6e87f.png)
  - 그리고 실제 참여도가 높은 참여자들이 가장 선호하는 특징은 습도 → 조도 → 온도 순으로 나타났다.
- **새로운 설문조사 예측 및 실제값**
  > **위에서 참여도가 높은 참여자들만으로 특정 건물 또는 호의 랜덤포레스트 학습 모델을 만들었다. 이제 새로운 설문조사 시뮬레이션을 돌려 참여도가 높은 참여자들의 설문점수 평균 값과 해당 모델의 예측값에 차이가 어느정도 나는지 확인해보도록 하자.**
![Untitled 9](https://user-images.githubusercontent.com/52296323/155922627-2a938370-63b9-4b0d-b07e-2088690113e9.png)
![Untitled 10](https://user-images.githubusercontent.com/52296323/155922637-98a90cfb-ec0d-4e0a-957a-b277cc8a6592.png)
  - 해당 모델은 1점의 오차도 안 되는 값으로 특정 건물 혹은 호의 참여도가 높은 참여자들의 평균 설문점수 값을 예측해냈다.
- **최적 특징 범위 구하기**
  > 참여도가 높은 참여자들을 토대로 훈련된 모델이 예측을 잘 해낼 수 있다는 것을 확인했다. 이제는 특징별로 어떤 범위에서 참여자들이 설문점수를 높게주는지, 그들이 만족하는지, 확인을 해보도록 하겠다.
  - 테스트 환경
    1. 온도, 습도, 조도 별로 값을 늘려갈 것이다. 온도를 올려주고 있을 때는 습도와 조도를 고정값으로 고정할 것이며, 습도를 올릴때는 온도와 조도를 고정 시킨 상태로 습도만 올리고와 같이 모델로 예측값을 뽑아낸다.
    2. 뽑아진 예측값의 이동평균을 구하여 특징별로 어떤 값의 범위에서 참여자들의 설문점수가 높게 나오는지 확인해보도록 하자.

![Untitled 11](https://user-images.githubusercontent.com/52296323/155922645-785b51eb-775f-42e6-91f5-a860892632bd.png)

![Untitled 12](https://user-images.githubusercontent.com/52296323/155922655-15027bb3-b916-4039-9763-7e7c0e424d2d.png)

![Untitled 13](https://user-images.githubusercontent.com/52296323/155922662-93a22093-ea91-470c-be78-4fd0d5be00f6.png)

![Untitled 14](https://user-images.githubusercontent.com/52296323/155922667-3b2c0ddc-456f-4501-b4cc-4be97e1c3d56.png)

![Untitled 15](https://user-images.githubusercontent.com/52296323/155922681-f021e441-c64b-44a8-a6ae-68a8d2c5e835.png)

![Untitled 16](https://user-images.githubusercontent.com/52296323/155922689-1fec7aa6-de2e-4f95-8c08-9c9de2aabd1a.png)

- 위의 특징별 구간은 실제로 임의의 선호 특징을 가지고 있는 사용자 객체를 만들기 전에 설정했던 [실내 적정값의 선호 구간안에 있는 구간] 이다.
- 오른쪽의 도표는 해당 구간의 모든 조합으로 모델을 예측하고, 사용자 객체에 설문조사를 실시한 값으로 약 3점정도의 오차를 보여줬다.
